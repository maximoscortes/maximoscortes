{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maximoscortes/maximoscortes/blob/main/andrexversor_bilstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz7foHBmj0f_",
        "outputId": "69bec7ad-dc7f-4f0f-f49a-2c75a6caa795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "epocas = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfg5BU3qW1uu",
        "outputId": "f3086171-7678-49c7-9397-f9a044d98f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting CherryPy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 14.6 MB/s \n",
            "\u001b[?25hCollecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 67.9 MB/s \n",
            "\u001b[?25hCollecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from CherryPy) (8.12.0)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->CherryPy) (1.15.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->CherryPy) (2022.1)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->CherryPy) (5.7.1)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->CherryPy) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->CherryPy) (57.4.0)\n",
            "Installing collected packages: jaraco.functools, jaraco.context, tempora, jaraco.text, jaraco.classes, zc.lockfile, portend, jaraco.collections, cheroot, CherryPy\n",
            "Successfully installed CherryPy-18.6.1 cheroot-8.6.0 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 portend-3.1.0 tempora-5.0.1 zc.lockfile-2.0\n",
            "Collecting cherrypy_cors\n",
            "  Downloading cherrypy_cors-1.6-py2.py3-none-any.whl (6.0 kB)\n",
            "Collecting httpagentparser>=1.5\n",
            "  Downloading httpagentparser-1.9.2.tar.gz (7.8 kB)\n",
            "Requirement already satisfied: cherrypy>=3 in /usr/local/lib/python3.7/dist-packages (from cherrypy_cors) (18.6.1)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy>=3->cherrypy_cors) (8.6.0)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.7/dist-packages (from cherrypy>=3->cherrypy_cors) (3.5.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy>=3->cherrypy_cors) (8.12.0)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from cherrypy>=3->cherrypy_cors) (3.1.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.7/dist-packages (from cherrypy>=3->cherrypy_cors) (2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy>=3->cherrypy_cors) (1.15.0)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy>=3->cherrypy_cors) (3.5.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.7/dist-packages (from portend>=2.1.1->cherrypy>=3->cherrypy_cors) (5.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy>=3->cherrypy_cors) (2022.1)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy>=3->cherrypy_cors) (3.7.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.7/dist-packages (from jaraco.collections->cherrypy>=3->cherrypy_cors) (3.2.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy>=3->cherrypy_cors) (5.7.1)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy>=3->cherrypy_cors) (4.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy>=3->cherrypy_cors) (3.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy>=3->cherrypy_cors) (57.4.0)\n",
            "Building wheels for collected packages: httpagentparser\n",
            "  Building wheel for httpagentparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httpagentparser: filename=httpagentparser-1.9.2-py2.py3-none-any.whl size=7555 sha256=440ee8b2cb2c9f8a55a9f6b63d9cd05fed453a4acdaeef2a94810b3e583ed757\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/d1/18/c7f7e8f375bc3779e61342a891cced69c03254348091c2c1f3\n",
            "Successfully built httpagentparser\n",
            "Installing collected packages: httpagentparser, cherrypy-cors\n",
            "Successfully installed cherrypy-cors-1.6 httpagentparser-1.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.signal as signal\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "\n",
        "import time\n",
        "import json\n",
        "from json import JSONEncoder\n",
        "!pip install CherryPy #webserver package\n",
        "!pip install cherrypy_cors\n",
        "\n",
        "\n",
        "\n",
        "# Frequency smoothing\n",
        "def freqSmooth(x, sm=1.0/24.0):\n",
        "    s = sm if sm > 1.0 else np.sqrt(2.0**sm)\n",
        "    N = len(x)\n",
        "    y = np.zeros_like(x)\n",
        "    for i in range(N):\n",
        "        i1 = max(int(np.floor(i/s)), 0)\n",
        "        i2 = min(int(np.floor(i*s)+1), N-1)\n",
        "        if i2 > i1:\n",
        "            y[i] = np.mean(x[i1:i2])\n",
        "    return y\n",
        "\n",
        "# FFT with frequency smoothing\n",
        "def plot_fft(x, fs, sm=1.0/24.0):\n",
        "    fft = freqSmooth(20 * np.log10(np.abs(np.fft.rfft(x) + 1.0e-9)), sm=sm)\n",
        "    freqs = np.fft.rfftfreq(len(x), 1.0 / fs)\n",
        "    return freqs, fft\n",
        "\n",
        "# load file from FMA dataset\n",
        "def load_fma_file(files, filepath, fs, N):\n",
        "    subfolder = files[random.randrange(0, len(files))]\n",
        "    subfolderpath = filepath + subfolder + '/'\n",
        "    subfiles = os.listdir(subfolderpath)\n",
        "    \n",
        "    mp3path = subfolderpath + subfiles[random.randrange(0, len(subfiles))]\n",
        "    x, sr = librosa.load(mp3path, sr=fs, mono=True)\n",
        "        \n",
        "    start_idx = int(random.uniform(0, len(x) - N))\n",
        "    return x[start_idx:start_idx+N]\n",
        "\n",
        "def plot_metric(history, key, val=True):\n",
        "    loss = history.history[key]\n",
        "    if val:\n",
        "        val_loss = history.history['val_' + key]\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.plot(epochs, loss, 'g.', label='Training ' + key)\n",
        "    if val:\n",
        "        plt.plot(epochs, val_loss, 'b', label='Validation ' + key)\n",
        "    plt.title('Training and validation ' + key)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key)\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def pre_emphasis_filter(x, coeff=0.85):\n",
        "    return tf.concat([x[:, 0:1, :], x[:, 1:, :] - coeff*x[:, :-1, :]], axis=1)\n",
        "\n",
        "def dc_loss(target_y, predicted_y):\n",
        "    return tf.reduce_mean(tf.square(tf.reduce_mean(target_y) - tf.reduce_mean(predicted_y))) / tf.reduce_mean(tf.square(target_y))\n",
        "\n",
        "# Error-to-signal loss\n",
        "def esr_loss(target_y, predicted_y, emphasis_func=lambda x : x):\n",
        "    target_yp = emphasis_func(target_y)\n",
        "    pred_yp = emphasis_func(predicted_y)\n",
        "    return tf.reduce_sum(tf.square(target_yp - pred_yp)) / tf.reduce_sum(tf.square(target_yp))\n",
        "\n",
        "class NumpyArrayEncoder(JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return JSONEncoder.default(self, obj)\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, loss_func, optimizer=keras.optimizers.Adam()):\n",
        "        self.model = keras.Sequential()\n",
        "        self.opt = optimizer\n",
        "        self.loss_func = loss_func\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.train_err = []\n",
        "        self.val_loss = []\n",
        "        self.val_err = []\n",
        "\n",
        "    def run_training(self, in_train, out_train, epoch_loss, epoch_error, N_skip, N_block):\n",
        "        N_samples = in_train.shape[1]\n",
        "        self.model.reset_states() # clear existing state\n",
        "        self.model(in_train[:, :N_skip, :]) # process some samples to build up state\n",
        "\n",
        "        # iterate over blocks\n",
        "        for n in range(N_skip, N_samples-N_block, N_block):\n",
        "            # compute loss\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = self.model(in_train[:, n:n+N_block, :])\n",
        "                loss = self.loss_func(out_train[:, n:n+N_block, :], y_pred)\n",
        "\n",
        "            # apply gradients\n",
        "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "            self.opt.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "\n",
        "            # update training metrics\n",
        "            epoch_loss.update_state(loss)\n",
        "            epoch_error.update_state(out_train[:, n:n+N_block, :], y_pred)\n",
        "\n",
        "    def run_validation(self, in_val, out_val, val_loss, val_error):\n",
        "        self.model.reset_states()\n",
        "        y_val = self.model(in_val)\n",
        "        loss = self.loss_func(out_val, y_val)\n",
        "        val_loss.update_state(loss)\n",
        "        val_error.update_state(out_val, y_val)\n",
        "\n",
        "    def run_epoch(self, epoch, in_train, out_train, in_val=None, out_val=None, N_skip=1000, N_block=2048):\n",
        "        start = time.perf_counter()\n",
        "        epoch_loss_avg = keras.metrics.Mean()\n",
        "        epoch_error = keras.metrics.MeanSquaredError()\n",
        "        val_loss_avg = keras.metrics.Mean()\n",
        "        val_error = keras.metrics.MeanSquaredError()\n",
        "\n",
        "        self.run_training(in_train, out_train, epoch_loss_avg, epoch_error, N_skip, N_block)\n",
        "        if in_val is not None:\n",
        "            self.run_validation(in_val, out_val, val_loss_avg, val_error)\n",
        "            \n",
        "        # end epoch\n",
        "        self.train_loss.append(epoch_loss_avg.result())\n",
        "        self.train_err.append(epoch_error.result())\n",
        "        self.val_loss.append(val_loss_avg.result())\n",
        "        self.val_err.append(val_error.result())\n",
        "        dur = time.perf_counter() - start\n",
        "\n",
        "        print(\"epocaaa {:03d} - tiempo: {:.4f}s, perdida: {:.4f}, error: {:.3%}, perdida de validacion: {:.4f}, Val_Error: {:.3%}\".format(            epoch+1, dur, epoch_loss_avg.result(), epoch_error.result(), val_loss_avg.result(), val_error.result()))\n",
        "\n",
        "    def train_until(self, loss_stop, in_train, out_train, in_val=None, out_val=None, N_skip=1000, N_block=2048):\n",
        "        epoch = 0\n",
        "        while True:\n",
        "            self.run_epoch(epoch, in_train, out_train, in_val, out_val, N_skip, N_block)\n",
        "\n",
        "            if self.train_loss[-1] < loss_stop:\n",
        "                break\n",
        "\n",
        "            epoch += 1\n",
        "\n",
        "    def train(self, num_epochs, in_train, out_train, in_val=None, out_val=None, N_skip=1000, N_block=2048, save_model=None, save_hist=None):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.run_epoch(epoch, in_train, out_train, in_val, out_val, N_skip, N_block)\n",
        "\n",
        "            if save_model is not None:\n",
        "                self.save_model(save_model)\n",
        "            if save_hist is not None:\n",
        "                self.save_history(save_hist)\n",
        "        \n",
        "        print(\"redi!\")\n",
        "\n",
        "\n",
        "    def plot_loss(self):\n",
        "        epochs = range(1, len(self.train_loss) + 1)\n",
        "        plt.plot(epochs, self.train_loss, 'g.', label='Training Loss')\n",
        "        plt.plot(epochs, self.val_loss, 'b', label='Validation Loss')\n",
        "        plt.title('Training and validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "    def plot_error(self):\n",
        "        epochs = range(1, len(self.train_loss) + 1)\n",
        "        plt.plot(epochs, self.train_err, 'g.', label='Training Error')\n",
        "        plt.plot(epochs, self.val_err, 'b', label='Validation Error')\n",
        "        plt.title('Training and validation Error')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Error')\n",
        "        plt.legend()\n",
        "\n",
        "    def save_model_json(self):\n",
        "        def get_layer_type(layer):\n",
        "            if isinstance(layer, keras.layers.TimeDistributed):\n",
        "                return 'time-distributed-dense'\n",
        "\n",
        "            if isinstance(layer, keras.layers.GRU):\n",
        "                return 'gru'\n",
        "\n",
        "            if isinstance(layer, keras.layers.Dense):\n",
        "                return 'dense'\n",
        "\n",
        "            if isinstance(layer, keras.layers.LSTM):\n",
        "                return 'lstm'\n",
        "\n",
        "            if isinstance(layer, keras.layers.Bidirectional):\n",
        "                return 'bi'\n",
        "\n",
        "            return 'unknown'\n",
        "\n",
        "        def save_layer(layer):\n",
        "            layercito = {\n",
        "                \"type\"    : get_layer_type(layer),\n",
        "                \"shape\"   : layer.output_shape,\n",
        "                \"weights\" : layer.get_weights()\n",
        "            }\n",
        "\n",
        "            return layercito\n",
        "\n",
        "\n",
        "        model_dict = {}\n",
        "        model_dict[\"in_shape\"] = self.model.input_shape\n",
        "        layers = []\n",
        "        for layer in self.model.layers:\n",
        "            layersote = save_layer(layer)\n",
        "            layers.append(layersote)\n",
        "\n",
        "        model_dict[\"layers\"] = layers\n",
        "        return model_dict\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        model_dict = self.save_model_json()\n",
        "        with open(filename, 'w') as outfile:\n",
        "            json.dump(model_dict, outfile, cls=NumpyArrayEncoder)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "    def load_model_json(self, json,indice):\n",
        "        in_shape = json[\"in_shape\"][1:]\n",
        "        self.model.add(keras.layers.InputLayer(input_shape=in_shape))\n",
        "        with open(\"headeR.h\", \"a\") as file:\n",
        "            file.write(\"\\n// Bloque de alturas numero \"+str(indice)+\" q se hace esto \\n\")\n",
        "            file.write(\"// LSP - 2022\\n\")\n",
        "            file.write(\"estructura_lstm1<8,float>  _pos\"+str(indice)+\"={\")\n",
        "            n_layer = 0\n",
        "            for layer in json[\"layers\"]:\n",
        "                print(in_shape)\n",
        "                #file.write('int dim_layer'+str(n_layer)+'='+str(in_shape)+';\\n')\n",
        "                weights = layer[\"weights\"]\n",
        "                np_weights = []\n",
        "                pesitos= str(weights)\n",
        "                pesotes = pesitos.replace('[','{')\n",
        "                pesotes = pesotes.replace(']','}')\n",
        "                pesotes = pesotes[:-1]\n",
        "                pesotes = pesotes[1:]\n",
        "                for w in weights:\n",
        "                    print(w)\n",
        "                    np_weights.append(np.array(w))\n",
        "                \n",
        "                if layer[\"type\"] == 'time-distributed-dense':\n",
        "                    file.write('\\n// pesos de tiempo distribuido denso numero '+str(n_layer)+'\\n'+str(pesotes)+',')\n",
        "                    d_layer = keras.layers.Dense(layer[\"shape\"][-1], activation='tanh')\n",
        "                    d_layer.build(input_shape=in_shape)\n",
        "                    d_layer.set_weights(np_weights)\n",
        "                    m_layer = keras.layers.TimeDistributed(d_layer)\n",
        "\n",
        "                elif layer[\"type\"] == 'gru':\n",
        "                    file.write('\\n// gru numero '+str(n_layer)+'\\n'+str(pesotes)+',')\n",
        "                    m_layer = keras.layers.GRU(units=layer[\"shape\"][-1], return_sequences=True)\n",
        "                    m_layer.build(input_shape=(None, None, in_shape[-1]))\n",
        "                    m_layer.set_weights(np_weights)\n",
        "\n",
        "                elif layer[\"type\"] == 'lstm':\n",
        "                    file.write('\\n// pesos de LSTM '+str(n_layer)+'\\n'+str(pesotes)+',')\n",
        "                    m_layer = keras.layers.LSTM(units=layer[\"shape\"][-1], activation=\"tanh\", return_sequences=True, recurrent_activation=\"sigmoid\", use_bias=True, kernel_initializer=\"glorot_uniform\", recurrent_initializer=\"orthogonal\", bias_initializer=\"random_normal\", unit_forget_bias=False)\n",
        "                    m_layer.build(input_shape=(None, None, in_shape[-1]))\n",
        "                    m_layer.set_weights(np_weights)\n",
        "\n",
        "                elif layer[\"type\"] == 'bi':\n",
        "                    file.write('\\n// pesos de bi-LSTM '+str(n_layer)+'\\n'+str(pesotes)+',')\n",
        "                    m_layer = keras.layers.Bidirectional(LSTM(units=layer[\"shape\"][-1], activation=\"tanh\", return_sequences=True, recurrent_activation=\"sigmoid\", use_bias=True, kernel_initializer=\"glorot_uniform\", recurrent_initializer=\"orthogonal\", bias_initializer=\"random_normal\", unit_forget_bias=False), merge_mode='sum' )\n",
        "                    m_layer.build(input_shape=(None, None, in_shape[-1]))\n",
        "                    m_layer.set_weights(np_weights)\n",
        "\n",
        "                \n",
        "                elif layer[\"type\"] == 'dense':\n",
        "                    file.write('\\n// pesos de denso normal numero '+str(n_layer)+'\\n'+str(pesotes) +'};')                   \n",
        "                    m_layer = keras.layers.Dense(layer[\"shape\"][-1])\n",
        "                    m_layer.build(input_shape=in_shape)\n",
        "                    m_layer.set_weights(np_weights)\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "                \n",
        "                in_shape = tuple(layer[\"shape\"])\n",
        "                self.model.add(m_layer)\n",
        "                n_layer = n_layer +1\n",
        "      \n",
        "    def load_model(self, filename,indice):\n",
        "        with open(filename, 'r') as json_file:\n",
        "            model_json = json.load(json_file)\n",
        "        self.load_model_json(model_json,indice)\n",
        "\n",
        "    def save_history(self, filename):\n",
        "        history = np.array([self.train_loss, self.train_err, self.val_loss, self.val_err])\n",
        "        np.savetxt(filename, history)\n",
        "\n",
        "    def load_history(self, filename):\n",
        "        history = np.loadtxt(filename)\n",
        "        self.train_loss = history[0].tolist()\n",
        "        self.train_err = history[1].tolist()\n",
        "        self.val_loss = history[2].tolist()\n",
        "        self.val_err = history[3].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_loss(target_y, predicted_y):\n",
        "    return esr_loss(target_y, predicted_y, pre_emphasis_filter) + dc_loss(target_y, predicted_y)\n",
        "\n",
        "\n",
        "def diplernin(indice):\n",
        "    mish = str(indice)\n",
        "    pathlist = Path('limpios'+mish).glob('*.wav')\n",
        "    clean_data = []\n",
        "    dist_data = []\n",
        "    NUM_SAMPLES = 20000\n",
        "\n",
        "    for p in tqdm(pathlist):\n",
        "        fs = 48000 #np.random.uniform(48000, 96000)\n",
        "        x, sr = librosa.load(str(p), sr=fs, mono=True)\n",
        "        N = len(x)\n",
        "        for wav_dir in ['susio'+mish+'/']:\n",
        "            y, sr = librosa.load(wav_dir + p.name, sr=fs, mono=True)\n",
        "            clean_data.append(x[N//2:N//2+NUM_SAMPLES])\n",
        "            dist_data.append(y[N//2:N//2+NUM_SAMPLES])\n",
        "            \n",
        "    print(\"test de falla:\")\n",
        "    print(clean_data)\n",
        "    #print(\"test de falla 2:\"+dist_data)\n",
        "    clean_data = np.asarray(clean_data)\n",
        "    dist_data = np.asarray(dist_data)\n",
        "    NUM_FILES = len(clean_data)\n",
        "    print(\"numero de archivos\", NUM_FILES)\n",
        "    NUM_TRAIN = int(NUM_FILES * 0.95)\n",
        "    NUM_VAL = NUM_FILES - NUM_TRAIN\n",
        "    NUM_INPUTS = 1\n",
        "    print(\"ahora despues de la conversion a np\")\n",
        "    print(clean_data)\n",
        "    print(\"num traib:\")\n",
        "    print(NUM_TRAIN)\n",
        "    x_train, x_val = np.split(clean_data, [NUM_TRAIN])  \n",
        "    y_train, y_val = np.split(dist_data,  [NUM_TRAIN])\n",
        "\n",
        "    print(\"xtrain:\")\n",
        "    print(x_train)\n",
        "    OUT_train  = np.reshape(y_train, (NUM_TRAIN, NUM_SAMPLES, 1))\n",
        "    OUT_val    = np.reshape(y_val, (NUM_VAL, NUM_SAMPLES, 1))\n",
        "    IN_train = np.reshape(x_train, (NUM_TRAIN, NUM_SAMPLES, NUM_INPUTS))\n",
        "    IN_val   = np.reshape(x_val, (NUM_VAL, NUM_SAMPLES, NUM_INPUTS))\n",
        "\n",
        "    #print(\"in train\", IN_train)\n",
        "\n",
        "    print(IN_train.dtype)\n",
        "    print(OUT_train.dtype)\n",
        "    \n",
        "    \n",
        "\n",
        "    np.save(\"info\"+mish+\"/out_train.npy\", OUT_train)\n",
        "    np.save(\"info\"+mish+\"/out_val.npy\", OUT_val)\n",
        "    np.save(\"info\"+mish+\"/in_train.npy\", IN_train)\n",
        "    np.save(\"info\"+mish+\"/in_val.npy\", IN_val)\n",
        "\n",
        "    OUT_train = np.load(\"info\"+mish+\"/out_train.npy\")\n",
        "    OUT_val   = np.load(\"info\"+mish+\"/out_val.npy\")\n",
        "    IN_train  = np.load(\"info\"+mish+\"/in_train.npy\")\n",
        "    IN_val    = np.load(\"info\"+mish+\"/in_val.npy\")\n",
        "\n",
        "    NUM_SAMPLES = 20000\n",
        "    NUM_INPUTS = 1\n",
        "    \n",
        "    if not os.path.exists('/content/modelos'):\n",
        "        os.makedirs('/content/modelos')\n",
        "\n",
        "          \n",
        "    model_file = 'modelos/andrex'+mish+'.json'\n",
        "    model_hist = 'modelos/andrex_history'+mish+'.txt'\n",
        "    model = Model(model_loss, optimizer=keras.optimizers.Adam(learning_rate=5.0e-4))\n",
        "    risal = os.path.exists(model_file)\n",
        "    if risal:\n",
        "        model.load_model(model_file,indice)\n",
        "        \n",
        "    else:\n",
        "        model.model.add(keras.layers.InputLayer(input_shape=(None, NUM_INPUTS)))\n",
        "        model.model.add(keras.layers.TimeDistributed(keras.layers.Dense(8, activation='tanh')))\n",
        "        #model.model.add(keras.layers.Bidirectional(LSTM(8, activation=\"tanh\", return_sequences=True, recurrent_activation=\"sigmoid\", use_bias=True, kernel_initializer=\"glorot_uniform\", recurrent_initializer=\"orthogonal\", bias_initializer=\"random_normal\", unit_forget_bias=False), merge_mode='sum'))\n",
        "        model.model.add(keras.layers.LSTM (16, activation=\"tanh\", return_sequences=True, recurrent_activation=\"sigmoid\", use_bias=True, kernel_initializer=\"glorot_uniform\", recurrent_initializer=\"orthogonal\", bias_initializer=\"random_normal\", unit_forget_bias=False))\n",
        "        model.model.add(keras.layers.Dense(1))\n",
        "\n",
        "    model.model.summary()\n",
        "\n",
        "    #print(\"in:\",IN_train, \"out:\",OUT_train, \"in:\",IN_val, \"out:\",OUT_val, model_file)\n",
        "    model.train(epocas, IN_train, OUT_train, IN_val, OUT_val, save_model=model_file, save_hist=model_hist)\n",
        "    #print(len(model.train_loss))\n",
        "    #print(model.train_loss[-1])\n",
        "    #print(model.val_loss[-1])\n",
        "    idx = 2\n",
        "    #predictions = model.model.predict(IN_train[idx].reshape(1, NUM_SAMPLES, NUM_INPUTS)).flatten()\n",
        "    #print(esr_loss(OUT_val, model.model.predict(IN_val)))\n",
        "    #print(esr_loss(OUT_train, model.model.predict(IN_train)))\n",
        "    model.save_model(model_file)\n",
        "    model.save_history(model_hist)\n",
        "    #files.download('modelos/andrex'+mish+'.json') \n",
        "    #files.download('modelos/andrex_history'+mish+'.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tw-TygRqcyX",
        "outputId": "2be36caf-3346-4ea4-f76d-777fb9c30733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "from google.colab import files\n",
        "import wave\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<head>\n",
        "\n",
        "Hola ! estamos funcionando perfecto ... sigamos avanzando!!!\n",
        "\n",
        "<meta http-equiv=\"allow\" content=\"HEAD,GET,PUT,DELETE,OPTIONS\" />\n",
        "</head>\n",
        "<body>\n",
        "<div>\n",
        "<p>\n",
        "<select id=\"audioSource\" visible=\"false\" ></select>\n",
        "</p>   \n",
        "</div>\n",
        "</body>\n",
        "<script>\n",
        "var opciones = [];\n",
        "var s = 0;\n",
        "var cosita = \"hola\";\n",
        "function gotDevices(deviceInfos) {\n",
        " \n",
        "\n",
        "  for (let i = 0; i !== deviceInfos.length; ++i) {\n",
        "    const deviceInfo = deviceInfos[i];\n",
        "    const option = document.createElement('option');\n",
        "    option.value = deviceInfo.deviceId;\n",
        "    \n",
        "    if (deviceInfo.kind === 'audioinput') {\n",
        "      //option.text = deviceInfo.label || `microphone ${audioInputSelect.length + 1}`;\n",
        "      //audioInputSelect.appendChild(option);\n",
        "      opciones[s]=deviceInfo.deviceId;\n",
        "      ++s;\n",
        "      console.log(\"opcion:\",deviceInfo.label);\n",
        "      if ( s == 1 ) { cosita = deviceInfo.deviceId; }\n",
        "      cosita = deviceInfo.deviceId;\n",
        "      //console.log(\"cosita:\",cosita);\n",
        "    }\n",
        "  }\n",
        "  //selectors.forEach((select, selectorIndex) => {\n",
        "  //  if (Array.prototype.slice.call(select.childNodes).some(n => n.value === values[selectorIndex])) {\n",
        "      \n",
        "  //    select.value = values[selectorIndex];\n",
        "      \n",
        "  //  }\n",
        "    \n",
        "  //});\n",
        "}\n",
        "\n",
        "\n",
        "function gotStream(stream) {\n",
        "\n",
        "\n",
        "gumStream = stream;\n",
        "  var options = {\n",
        "\n",
        "    mimeType : 'audio/webm'  };           //  mimeType : 'audio/webm;codecs=pcm'  };       \n",
        "  \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  datito = [];\n",
        "  //recorder.reset();\n",
        "  recorder.ondataavailable = function(e) { \n",
        "    datito.push(e.data);\n",
        "               \n",
        "    var url = new URL.createObjectURL(datito);// e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    } };\n",
        "  recorder.start;\n",
        "\n",
        "  /*\n",
        "  window.stream = stream; \n",
        "  \n",
        "  rec = new MediaRecorder(stream);\n",
        "  rec.ondataavailable = e => {\n",
        "    audioChunks.push(e.data);\n",
        "    if (rec.state == \"inactive\"){\n",
        "      let blob = new Blob(audioChunks,{type:'audio/wav;codecs=pcm'});\n",
        "      recordedAudio.src = URL.createObjectURL(blob);\n",
        "      recordedAudio.controls=true;\n",
        "      recordedAudio.autoplay=true;\n",
        "      audioDownload.href = recordedAudio.src;\n",
        "      audioDownload.download = 'wav';\n",
        "      audioDownload.innerHTML = 'download';\n",
        "    }\n",
        "  }\n",
        "  */\n",
        "}\n",
        "\n",
        "function handleError(error) {\n",
        "  console.log('navigator.MediaDevices.getUserMedia error: ', error.message, error.name);\n",
        "}\n",
        "\n",
        "//function start() {\n",
        "\t// Second call to getUserMedia() with changed device may cause error, so we need to release stream before changing device\n",
        "//  if (window.stream) {\n",
        "//  \tstream.getAudioTracks()[0].stop();\n",
        "//  }\n",
        "\n",
        "//}\n",
        "\n",
        "\n",
        "//audioInputSelect.onchange = start;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "var data;\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"listoco\";\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "    var my_div = document.createElement(\"DIV\");\n",
        "    var my_p = document.createElement(\"P\");\n",
        "    var my_btn = document.createElement(\"BUTTON\");\n",
        "    var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "    my_btn.appendChild(t);\n",
        "    my_div.appendChild(my_btn);\n",
        "    document.body.appendChild(my_div);\n",
        "\n",
        "    var base64data = 0;\n",
        "    var reader;\n",
        "    var recorder, gumStream;\n",
        "    var recordButton = my_btn;\n",
        "\n",
        " navigator.mediaDevices.enumerateDevices()\n",
        ".then(gotDevices).then(pipi)\n",
        ".catch(handleError);\n",
        "\n",
        "function pipi(){\n",
        "\n",
        "\n",
        "\n",
        "    var handleSuccess = function(stream) {\n",
        "      gumStream = stream;\n",
        "      var options = {\n",
        "        mimeType : 'audio/webm;codecs=pcm'\n",
        "      };            \n",
        "      recorder = new MediaRecorder(stream, options);\n",
        "      recorder.ondataavailable = function(e) {            \n",
        "        var url = URL.createObjectURL(e.data);\n",
        "        var preview = document.createElement('audio');\n",
        "        preview.controls = true;\n",
        "        preview.src = url;\n",
        "        document.body.appendChild(preview);\n",
        "\n",
        "        reader = new FileReader();\n",
        "        reader.readAsDataURL(e.data); \n",
        "        reader.onloadend = function() {\n",
        "          base64data = reader.result;\n",
        "          \n",
        "        }\n",
        "      };\n",
        "      \n",
        "      recorder.start();\n",
        "      };\n",
        "\n",
        "\n",
        "\n",
        "    console.log(\"cosita:\",cosita);\n",
        "      var audioSource = opciones[7];\n",
        "      console.log(\"este es el inputaudioSource\",audioSource, \" audio \",opciones[6]);\n",
        "      console.log(\"estas las opciones\",opciones);\n",
        "      const constraints = {\n",
        "        audio: {\n",
        "              autoGainControl: false,\n",
        "        channelCount: 2,\n",
        "        echoCancellation: false,\n",
        "        latency: 0,\n",
        "        noiseSuppression: false,\n",
        "        sampleRate: 48000,\n",
        "        sampleSize: 24,\n",
        "        volume: 1.0,\n",
        "        deviceId: audioSource }};\n",
        "      console.log(\"ahora estos\",constraints);\n",
        "\n",
        "      navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess).catch(handleError);\n",
        "\n",
        "    recordButton.innerText = \"Recording... press to stop\";\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "setTimeout(function () { recordButton.click(); }, 6000); //cantidad de segundos de grabacion !\n",
        "\n",
        "\n",
        "\n",
        "function pipipi(){\n",
        "  \n",
        "    \n",
        "\n",
        "    data = new Promise(resolve=>{\n",
        "    recordButton.onclick = () =>{\n",
        "    toggleRecording();\n",
        "\n",
        "    sleep(2000).then(() => {\n",
        "\n",
        "      resolve(base64data.toString())\n",
        "      \n",
        "    });\n",
        "\n",
        "    }\n",
        "    });\n",
        " return data;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "data = pipipi();\n",
        " \n",
        "   \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True) #-ss 00:00:20 -to 00:00:40\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "  \n",
        "  return audio, sr\n",
        "\n",
        "def save_wav_channel(fn, wav, channel):\n",
        "    '''\n",
        "    Take Wave_read object as an input and save one of its\n",
        "    channels into a separate .wav file.\n",
        "    '''\n",
        "    # Read data\n",
        "    nch   = wav.getnchannels()\n",
        "    depth = wav.getsampwidth()\n",
        "    wav.setpos(0)\n",
        "    sdata = wav.readframes(wav.getnframes())\n",
        "\n",
        "    # Extract channel data (24-bit data not supported)\n",
        "    typ = { 1: np.uint8, 2: np.uint16, 4: np.uint32 }.get(depth)\n",
        "    if not typ:\n",
        "        raise ValueError(\"sample width {} not supported\".format(depth))\n",
        "    if channel >= nch:\n",
        "        raise ValueError(\"cannot extract channel {} out of {}\".format(channel+1, nch))\n",
        "    #print (\"Extracting channel {} out of {} channels, {}-bit depth\".format(channel+1, nch, depth*8))\n",
        "    data = np.fromstring(sdata, dtype=typ)\n",
        "    ch_data = data[channel::nch]\n",
        "\n",
        "    # Save channel to a separate file\n",
        "    outwav = wave.open(fn, 'w')\n",
        "    outwav.setparams(wav.getparams())\n",
        "    outwav.setnchannels(1)\n",
        "    outwav.writeframes(ch_data.tostring())\n",
        "    outwav.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "XlkmMjjv972H",
        "outputId": "f196bce9-9d08-40a8-8c0e-d32e5785d312"
      },
      "outputs": [],
      "source": [
        "#sampleo y entrenamiento\n",
        "from os import remove\n",
        "\n",
        "\n",
        "import cherrypy_cors\n",
        "from google.colab import files\n",
        "import cherrypy\n",
        "numero = 31\n",
        "import scipy.io.wavfile\n",
        "from google.colab.output import eval_js\n",
        "pulentisimo = eval_js(\"google.colab.kernel.proxyPort(8888)\")\n",
        "print(pulentisimo+'/a')\n",
        "import subprocess\n",
        "subprocess.Popen([\"python\", \"/content/test.py\", \"8888\"]) \n",
        "f = open(\"direccion.pan\", \"w\")\n",
        "f.write(pulentisimo)\n",
        "f.close()\n",
        "FINFIN= \"\"\" \n",
        "<script>location.reload();</script>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wave\n",
        "import sys\n",
        "\n",
        "\n",
        "while numero < 100:\n",
        "    mish = str(numero)\n",
        "    if not os.path.exists('/content/limpios'+mish):\n",
        "        os.makedirs('/content/limpios'+mish)\n",
        "    if not os.path.exists('/content/susio'+mish):\n",
        "        os.makedirs('/content/susio'+mish)\n",
        "    if not os.path.exists('/content/info'+mish):\n",
        "        os.makedirs('/content/info'+mish)\n",
        "    on = 0\n",
        "    while on < 2:\n",
        "        audio = []\n",
        "        f = open(\"sinimportancia.chu\", \"w\")\n",
        "        f.write(str(numero))\n",
        "        f.close()\n",
        "        mish = str(numero)\n",
        "        audio, sr = get_audio()  # aqui recolecta el audio de javascript !!!\n",
        "        filon = \"doble\"+str(on)+\".wav\"\n",
        "        print(\"filon : \"+ filon)\n",
        "        #audion = audio[sr*2..length(audio)] #for ()\n",
        "        audion= []\n",
        "        eee = 0\n",
        "        print(\"el coson:\"+str(sr*2)+\" y el otro \"+str(len(audio)))\n",
        "        #for uuu in range(sr*2,len(audio)):\n",
        "          #print(\"eee:\"+str(eee)+\" uuu:\"+str(uuu))\n",
        "          #audion[eee] = audio[uuu]  \n",
        "          #eee=eee+1\n",
        "        #print(\"aki esta el coso del coso nuevo:\"+audio)\n",
        "        #print(\"aki esta el coso del coso nuevo 2:\"+audion)\n",
        "        scipy.io.wavfile.write(filon, sr, audio)\n",
        "        wav = wave.open(filon)\n",
        "        filote = '/content/limpios'+mish+'/sample'+str(on)+'.wav'\n",
        "        filotin = '/content/susio'+mish+'/sample'+str(on)+'.wav'\n",
        "        save_wav_channel('/content/limpios'+mish+'/sample'+str(on)+'.wav', wav, 0)\n",
        "        save_wav_channel('/content/susio'+mish+'/sample'+str(on)+'.wav', wav, 1)\n",
        "        print(\"sample rate de la conversion:\",sr)\n",
        "        remove(filon)\n",
        "        on = on + 1\n",
        "        #display(HTML(FINFIN))\n",
        "        spf = wave.open(filote, \"r\")\n",
        "        spf2 = wave.open(filotin, \"r\")\n",
        "        # Extract Raw Audio from Wav File\n",
        "        signal = spf.readframes(-1)\n",
        "        signal2 = spf2.readframes(-1)\n",
        "        print(signal)\n",
        "        signal = np.frombuffer(signal)#, \"Int16\")\n",
        "        signal2 = np.frombuffer(signal2)#, \"Int16\")\n",
        "      \n",
        "        #plt.figure(1)\n",
        "        #plt.subplot(211)\n",
        "        #plt.plot(signal, color=\"red\")\n",
        "        #plt.subplot(212)\n",
        "        #plt.title(\"Signal Wave...\")\n",
        "        #plt.plot(signal2, color=\"green\")\n",
        "        #plt.show()\n",
        "       \n",
        "\n",
        "    diplernin(numero)\n",
        "    numero = numero + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymQ4OiyCx2yW"
      },
      "outputs": [],
      "source": [
        "#fabricacion de encabezado de c++\n",
        "\n",
        "archivosjason = Path('modelos').glob('*.json')\n",
        "if os.path.exists(\"headeR.h\"):\n",
        "    os.remove(\"headeR.h\")\n",
        "\n",
        "with open(\"headeR.h\", \"a\") as file:\n",
        "    file.write(\"// este va en el private del punto H\\n\")\n",
        "    file.write(\"std::unique_ptr<modelo_lstm1<8>> _LSTM[100];\\n\")\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"// este al inicializar\\n\")\n",
        "    for i in range(100):\n",
        "        file.write(\"_LSTM[\"+str(i)+\"] = std::make_unique<modelo_lstm1<8>>(_pos\"+str(i)+\");\\n\")\n",
        "\n",
        "\n",
        "model = Model(model_loss, optimizer=keras.optimizers.Adam(learning_rate=5.0e-4))\n",
        "for n in tqdm(archivosjason):\n",
        "        \n",
        "        #str(n)\n",
        "        for wav_dir in ['modelos/']:\n",
        "            model_file=wav_dir + n.name\n",
        "            phone_number = model_file\n",
        "            dd = ''.join([n for n in phone_number if n.isdigit()])\n",
        "            ddd = int(dd)\n",
        "            print(phone_number,dd,ddd)\n",
        "            model.load_model(model_file,ddd)\n",
        "            #print(model)\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQW3s73EBQSC"
      },
      "outputs": [],
      "source": [
        "#partir wav en pedazitos\n",
        "\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "\n",
        "class SplitWavAudioMubin():\n",
        "    def __init__(self, folder, filename):\n",
        "        self.folder = folder\n",
        "        self.filename = filename\n",
        "        self.filepath = folder + '/' + filename\n",
        "        \n",
        "        self.audio = AudioSegment.from_wav(self.filepath)\n",
        "    \n",
        "    def get_duration(self):\n",
        "        return self.audio.duration_seconds\n",
        "    \n",
        "    def single_split(self, from_min, to_min, split_filename):\n",
        "        t1 = from_min * 60 * 1000\n",
        "        t2 = to_min * 60 * 1000\n",
        "        split_audio = self.audio[t1:t2]\n",
        "        split_audio.export(self.folder + '/' + split_filename, format=\"wav\")\n",
        "        \n",
        "    def multiple_split(self, min_per_split):\n",
        "        total_mins = math.ceil(self.get_duration() / 60)\n",
        "        for i in range(0, total_mins, min_per_split):\n",
        "            split_fn = str(i) + '_' + self.filename\n",
        "            self.single_split(i, i+min_per_split, split_fn)\n",
        "            #print(str(i) + ' Done')\n",
        "            if i == total_mins - min_per_split:\n",
        "                #print('All splited successfully')\n",
        "\n",
        "folder = '.'\n",
        "file = 'doble0.wav'\n",
        "split_wav = SplitWavAudioMubin(folder, file)\n",
        "split_wav.multiple_split(min_per_split=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw2RPb91EorZ"
      },
      "outputs": [],
      "source": [
        "#test.py\n",
        "\n",
        "import cherrypy\n",
        "import sys\n",
        "import random\n",
        "import string\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "#print(pulentisimo)\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.parse_args()\n",
        "\n",
        "class HelloWorld:\n",
        "    @cherrypy.expose\n",
        "    def index(self):\n",
        "        f = open(\"sinimportancia.chu\", \"r\")\n",
        "        return f.read()\n",
        "    @cherrypy.expose\n",
        "    def a(self, length=8):\n",
        "        f = open(\"direccion.pan\", \"r\")\n",
        "        direcsaund = f.read()   #aki va la direcsion html\n",
        "        htttp =  '''\n",
        "        <!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <p style=\"color: forestgreen;\">\n",
        "  <title>..::cosito del coso rulezx::..</title>\n",
        "\n",
        "  en este script se esta cocinando todo lo relacionado con \n",
        "  comunicacion desde el compu hacia el arduino\n",
        "  se envia un codigo correspondiente \n",
        "  a la posicion q el robot \n",
        "  necesita y el \n",
        "  arduino lo \n",
        "  hace\n",
        "\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "  <div class=\"serial-scale-div\">\n",
        "        <button class=\"btn\" id=\"connect-to-serial\">enganchar puerto</button>\n",
        "  </div>\n",
        "\n",
        "\n",
        "  <button id=\"put-serial-messages\">manda mensaje hola</button>\n",
        "\n",
        "  <button id=\"get-serial-messages\">lee mensajes</button>\n",
        "  \n",
        "  <div id=\"serial-messages-container\">\n",
        "    <div class=\"message\"></div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "var writer;// = port.writable.getWriter();\n",
        "document.body.style.backgroundColor = \"green\";\n",
        "//document.write(str.fontcolor( \"green\" ));\n",
        "\n",
        "    \"use strict\";\n",
        "    class SerialScaleController {\n",
        "        constructor() {\n",
        "            this.encoder = new TextEncoder();\n",
        "            this.decoder = new TextDecoder();\n",
        "        }\n",
        "        async init() {\n",
        "            if ('serial' in navigator) {\n",
        "                try {\n",
        "                    const port = await navigator.serial.requestPort();\n",
        "                    await port.open({ baudRate: 9600 });\n",
        "                    this.reader = port.readable.getReader();\n",
        "                    let signals = await port.getSignals();\n",
        "                    console.log(signals);\n",
        "                    writer = port.writable.getWriter();\n",
        "                }\n",
        "                catch (err) {\n",
        "                    console.error('There was an error opening the serial port:', err);\n",
        "                }\n",
        "            }\n",
        "            else {\n",
        "                console.error('Web serial doest seem to be enabled in your browser. Try enabling it by visiting:');\n",
        "                console.error('chrome://flags/#enable-experimental-web-platform-features');\n",
        "                console.error('opera://flags/#enable-experimental-web-platform-features');\n",
        "                console.error('edge://flags/#enable-experimental-web-platform-features');\n",
        "            }\n",
        "        }\n",
        "        async escribe() {\n",
        "\n",
        "            \n",
        "            const data = new Uint8Array([parseInt(piopio)]); // hello\n",
        "            //const data = new String([parseInt(piopio)]); // hello\n",
        "            console.log(\"el data\",data);\n",
        "            await writer.write(data);\n",
        "\n",
        "\n",
        "            // Allow the serial port to be closed later.\n",
        "            //writer.releaseLock();\n",
        "            return \" enviado:\"+data+\" \";\n",
        "        }\n",
        "        async read() {\n",
        "            \n",
        "            try {\n",
        "                const readerData = await this.reader.read();\n",
        "                console.log(\"datos leidos:\",readerData)\n",
        "                return this.decoder.decode(readerData.value);\n",
        "            }\n",
        "            catch (err) {\n",
        "                const errorMessage = `error reading data: ${err}`;\n",
        "                console.error(errorMessage);\n",
        "                return errorMessage;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    const serialScaleController = new SerialScaleController();\n",
        "    const connect = document.getElementById('connect-to-serial');\n",
        "    const getSerialMessages = document.getElementById('get-serial-messages');\n",
        "    const putSerialMessages = document.getElementById('put-serial-messages');\n",
        "    \n",
        "    connect.addEventListener('pointerdown', () => {\n",
        "      serialScaleController.init();\n",
        "    });\n",
        "\n",
        "    getSerialMessages.addEventListener('pointerdown', async () => {\n",
        "      getSerialMessage();\n",
        "    });\n",
        "\n",
        "    putSerialMessages.addEventListener('pointerdown', async () => {\n",
        "      putSerialMessage();\n",
        "    });\n",
        "\n",
        "    async function getSerialMessage() {\n",
        "      document.querySelector(\"#serial-messages-container .message\").innerText += await serialScaleController.read()\n",
        "    }\n",
        "\n",
        "    async function putSerialMessage() {\n",
        "      document.querySelector(\"#serial-messages-container .message\").innerText += await serialScaleController.escribe()\n",
        "    }\n",
        "var piopio = ''; \n",
        "function capturanumero() {\n",
        "\n",
        "fetch(' ''' \n",
        "        htttp = htttp + direcsaund + ''' ')\n",
        "  .then(response => response.text())  .then((data) => {\n",
        "    //console.log(\"paso el coso:\",data)\n",
        "    piopio = data\n",
        "  });\n",
        "  console.log(\"estamos en esta configuracion, la numero \",piopio);\n",
        "  \n",
        "  putSerialMessage();\n",
        "  getSerialMessage();\n",
        "\n",
        "  }\n",
        "\n",
        "\n",
        "    setInterval('capturanumero()',2000);\n",
        "\n",
        "\n",
        "  </script>\n",
        "</body>\n",
        "</html>'''\n",
        "        return htttp\n",
        "    index.exposed = True\n",
        "\n",
        "#\n",
        "if __name__ == '__main__':\n",
        "    #elpulento = eval_js('google.colab.kernel.proxyPort(8888)')\n",
        "    config = {'server.socket_host': '0.0.0.0','server.socket_port' : int(sys.argv[1])}\n",
        "    cherrypy.config.update(config)\n",
        "    cherrypy.quickstart(HelloWorld())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjvfpDwMsmTt"
      },
      "outputs": [],
      "source": [
        "import cherrypy\n",
        "\n",
        "class HelloWorld(object):\n",
        "    @cherrypy.expose\n",
        "    def index(self):\n",
        "        return 'Hello World!'\n",
        "\n",
        "    @cherrypy.expose\n",
        "    def greet(self, name):\n",
        "        return 'Hello {}!'.format(name)\n",
        "\n",
        "cherrypy.quickstart(HelloWorld())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH3OcpevUhMN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfQRLtFEGRLo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "andrexversor_bilstm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}